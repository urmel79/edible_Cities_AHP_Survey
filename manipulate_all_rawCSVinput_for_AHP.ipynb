{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4266f6-c35a-45ba-99cf-10731fdbad32",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Why we use a [Jupyter](https://en.wikipedia.org/wiki/Project_Jupyter) notebook to to publish the R program examples:\n",
    "\n",
    "Jupyter is a new **open source** alternative to the proprietary numerical software [Mathematica](https://en.wikipedia.org/wiki/Wolfram_Mathematica) from **Wolfram Research** that is well on the way to becoming a **standard for exchanging research results** (<cite data-cite=\"Scientific_Paper_obsolete_2018\">Somers, 2018</cite>; <cite data-cite=\"Future_of_Research_Paper_2018\">Romer, 2018</cite>).\n",
    "\n",
    "Originally Jupyter was intended as an IDE for the programming languages **Julia** and **Python**. Besides that it is also possible to install other interpreter kernels, such as the **[IRkernel](https://irkernel.github.io/installation/)** for R. This can be interesting if the IDE **RStudio Desktop** is not available on the target platform used. For example, it is very difficult to install RStudio on the ARM-based embedded computer **Raspberry Pi** due to many technical dependencies. In contrast, using the R kernel in JupyterLab on the Raspberry Pi works very well and performant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685263b8-8a36-40f2-973d-401e5ce0116b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Global settings and dependencies\n",
    "\n",
    "## Install missing packages if not present yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0dd6c0-217b-4a72-af09-a86b2fabf834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"All required packages are installed.\"\n"
     ]
    }
   ],
   "source": [
    "list.of.packages <- c(\"data.table\")\n",
    "new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]\n",
    "if(length(new.packages)) {\n",
    "    install.packages(new.packages)\n",
    "} else {\n",
    "    print(\"All required packages are installed.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11b1cb-3708-4fe7-b80a-07ff02070a79",
   "metadata": {},
   "source": [
    "## Load package `data.table`\n",
    "\n",
    "The package `data.table` is used for reading and manipulating tables (`data.table` inherits from `data.frame`). Install and load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81b50219-59aa-4292-be89-1f4cfc97e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e090cf2-d697-4f66-9f9b-9806406fdeb8",
   "metadata": {},
   "source": [
    "## Set globally used input and output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2383fc4e-8a5a-4834-8216-e269151185a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_input_path = \"./input_data_from_survey\"\n",
    "str_output_path = \"./output_data_manipulated\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657abd23-18f5-41bb-baf4-e584efb2d0e3",
   "metadata": {},
   "source": [
    "## Create data frame (table) handling the file names of input CSV data (raw data from survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "513c1ac2-6979-4726-a9f3-eab1e1e5ff4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 4 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>file_idx</th><th scope=col>keys</th><th scope=col>filenames</th><th scope=col>descriptions</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>all</td><td>rdata_all_AHP_edible_Cities_2022-03-18_09-53.csv</td><td>all target groups together         </td></tr>\n",
       "\t<tr><td>2</td><td>CA </td><td>rdata_CA_AHP_edible_Cities_2022-03-18_10-28.csv </td><td>from city administrations          </td></tr>\n",
       "\t<tr><td>3</td><td>NGO</td><td>rdata_NGO_AHP_edible_Cities_2022-03-18_10-40.csv</td><td>from non-governmental organisations</td></tr>\n",
       "\t<tr><td>4</td><td>PE </td><td>rdata_PE_AHP_edible_Cities_2022-03-18_10-41.csv </td><td>practitioners and experts          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 4 × 4\n",
       "\\begin{tabular}{llll}\n",
       " file\\_idx & keys & filenames & descriptions\\\\\n",
       " <int> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 1 & all & rdata\\_all\\_AHP\\_edible\\_Cities\\_2022-03-18\\_09-53.csv & all target groups together         \\\\\n",
       "\t 2 & CA  & rdata\\_CA\\_AHP\\_edible\\_Cities\\_2022-03-18\\_10-28.csv  & from city administrations          \\\\\n",
       "\t 3 & NGO & rdata\\_NGO\\_AHP\\_edible\\_Cities\\_2022-03-18\\_10-40.csv & from non-governmental organisations\\\\\n",
       "\t 4 & PE  & rdata\\_PE\\_AHP\\_edible\\_Cities\\_2022-03-18\\_10-41.csv  & practitioners and experts          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 4 × 4\n",
       "\n",
       "| file_idx &lt;int&gt; | keys &lt;chr&gt; | filenames &lt;chr&gt; | descriptions &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | all | rdata_all_AHP_edible_Cities_2022-03-18_09-53.csv | all target groups together          |\n",
       "| 2 | CA  | rdata_CA_AHP_edible_Cities_2022-03-18_10-28.csv  | from city administrations           |\n",
       "| 3 | NGO | rdata_NGO_AHP_edible_Cities_2022-03-18_10-40.csv | from non-governmental organisations |\n",
       "| 4 | PE  | rdata_PE_AHP_edible_Cities_2022-03-18_10-41.csv  | practitioners and experts           |\n",
       "\n"
      ],
      "text/plain": [
       "  file_idx keys filenames                                       \n",
       "1 1        all  rdata_all_AHP_edible_Cities_2022-03-18_09-53.csv\n",
       "2 2        CA   rdata_CA_AHP_edible_Cities_2022-03-18_10-28.csv \n",
       "3 3        NGO  rdata_NGO_AHP_edible_Cities_2022-03-18_10-40.csv\n",
       "4 4        PE   rdata_PE_AHP_edible_Cities_2022-03-18_10-41.csv \n",
       "  descriptions                       \n",
       "1 all target groups together         \n",
       "2 from city administrations          \n",
       "3 from non-governmental organisations\n",
       "4 practitioners and experts          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_csvInputFiles <- data.table(\n",
    "  file_idx = 1:4,\n",
    "  keys = c(\"all\", \"CA\", \"NGO\", \"PE\"),\n",
    "  filenames = c(\"rdata_all_AHP_edible_Cities_2022-03-18_09-53.csv\",\n",
    "                \"rdata_CA_AHP_edible_Cities_2022-03-18_10-28.csv\",\n",
    "                \"rdata_NGO_AHP_edible_Cities_2022-03-18_10-40.csv\",\n",
    "                \"rdata_PE_AHP_edible_Cities_2022-03-18_10-41.csv\"),\n",
    "  descriptions = c(\"all target groups together\",\n",
    "                   \"from city administrations\",\n",
    "                   \"from non-governmental organisations\",\n",
    "                   \"practitioners and experts\")\n",
    ")\n",
    "\n",
    "#print(df_csvInputFiles)\n",
    "# See first few rows\n",
    "head(df_csvInputFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace923ec-141f-4537-923d-ed6c18ad699f",
   "metadata": {},
   "source": [
    "# Functions for manipulation of raw CSV input data of survey\n",
    "\n",
    "## Function for reading in survey data from CSV files to data frame objects\n",
    "\n",
    "Define a function for reading in a CSV file to 4 different date frames by selecting different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "925879d2-aa01-483e-97de-fd9ff863e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_readCSVdata_to_dataframes <- function(str_CSVfilename) {\n",
    "  \n",
    "  df_mySurvey_1 <- fread(\n",
    "    file = str_CSVfilename, encoding = \"UTF-8\",\n",
    "    header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
    "    # dec = \".\", row.names = \"CASE\",\n",
    "    select = c(\"CASE\", \"AU01\", \"AU02\", \"AU03\", \n",
    "               \"RU01_01\", \"RU02_01\", \"RU03_01\", \"RU04_01\", \"RU05_01\", \"RU06_01\")\n",
    "    )\n",
    "  \n",
    "  df_mySurvey_2 <- fread(\n",
    "    file = str_CSVfilename, encoding = \"UTF-8\",\n",
    "    header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
    "    # dec = \".\", row.names = \"CASE\",\n",
    "    select = c(\"CASE\", \"AS01\", \"AS02\", \"AS03\", \n",
    "               \"RS01_01\", \"RS02_01\", \"RS03_01\", \"RS04_01\", \"RS05_01\", \"RS06_01\")\n",
    "    )\n",
    "  \n",
    "  df_mySurvey_3 <- fread(\n",
    "    file = str_CSVfilename, encoding = \"UTF-8\",\n",
    "    header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
    "    # dec = \".\", row.names = \"CASE\",\n",
    "    select = c(\"CASE\", \"AW01\", \"AW02\", \"AW03\", \n",
    "               \"RW01_01\", \"RW02_01\", \"RW03_01\", \"RW04_01\", \"RW05_01\", \"RW06_01\")\n",
    "    )\n",
    "  \n",
    "  df_mySurvey_4 <- fread(\n",
    "    file = str_CSVfilename, encoding = \"UTF-8\",\n",
    "    header = TRUE, sep = \"\\t\", quote = \"\\\"\",\n",
    "    # dec = \".\", row.var = \"CASE\",\n",
    "    select = c(\"CASE\", \"AK01\", \"AK02\", \"AK03\", \n",
    "               \"RK01_01\", \"RK02_01\", \"RK03_01\", \"RK04_01\", \"RK05_01\", \"RK06_01\")\n",
    "    )\n",
    "  \n",
    "  output <- list(df_mySurvey_1, df_mySurvey_2, df_mySurvey_3, df_mySurvey_4)\n",
    "  \n",
    "  return(output)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174d878-6a9e-4d8c-92d7-8b64c2e3d7c7",
   "metadata": {},
   "source": [
    "## Function for manipulation of the read in data and store in new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0045f26b-73f7-4d1a-94f5-40bc42f84a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_scrambleData <- function(df_inputData, vec_colnames_search_1, vec_colnames_search_2, vec_colnames_out) {\n",
    "  # Generate new data frame ...\n",
    "  df_outputData <- data.frame(matrix(ncol = 3, nrow = 0))\n",
    "  # ... and name the columns\n",
    "  colnames(df_outputData) <- vec_colnames_out\n",
    "  \n",
    "  # Generate 1. column\n",
    "  for ( row_idx in 1:nrow(df_inputData) ) {\n",
    "    # filter column names by vector element\n",
    "    if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[1], with=FALSE] == 1) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[1], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val * -1 - 1\n",
    "\n",
    "      df_outputData[row_idx, vec_colnames_out[1]] <- int_tmp_val\n",
    "    }\n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[1], with=FALSE] == -1) {\n",
    "      df_outputData[row_idx, vec_colnames_out[1]] <- 1\n",
    "    }\n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[1], with=FALSE] == 2) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[2], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val + 1\n",
    "\n",
    "      df_outputData[row_idx, vec_colnames_out[1]] <- int_tmp_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Generate 2. column\n",
    "  for ( row_idx in 1:nrow(df_inputData) ) {\n",
    "    # filter column names by vector element\n",
    "    if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[2], with=FALSE] == 1) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[3], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val * -1 - 1\n",
    "      \n",
    "      df_outputData[row_idx, vec_colnames_out[2]] <- int_tmp_val\n",
    "    } \n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[2], with=FALSE] == -1) {\n",
    "      df_outputData[row_idx, vec_colnames_out[2]] <- 1\n",
    "    } \n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[2], with=FALSE] == 2) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[4], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val + 1\n",
    "      \n",
    "      df_outputData[row_idx, vec_colnames_out[2]] <- int_tmp_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # Generate 3. column\n",
    "  for ( row_idx in 1:nrow(df_inputData) ) {\n",
    "    # filter column names by vector element\n",
    "    if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[3], with=FALSE] == 1) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[5], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val * -1 - 1\n",
    "      \n",
    "      df_outputData[row_idx, vec_colnames_out[3]] <- int_tmp_val\n",
    "    } \n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[3], with=FALSE] == -1) {\n",
    "      df_outputData[row_idx, vec_colnames_out[3]] <- 1\n",
    "    } \n",
    "    else if (df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_1[3], with=FALSE] == 2) {\n",
    "      int_tmp_val <- as.integer(df_inputData[row_idx, colnames(df_inputData) %in% vec_colnames_search_2[6], with=FALSE])\n",
    "      int_tmp_val <- int_tmp_val + 1\n",
    "      \n",
    "      df_outputData[row_idx, vec_colnames_out[3]] <- int_tmp_val\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  # return scrambled data frame\n",
    "  return(df_outputData)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288d2bf-a084-4843-9d3e-5b841f5d4c11",
   "metadata": {},
   "source": [
    "## Function for writing resulting data frame to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da629582-2ad9-4c40-8041-961c3d9859b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_writeDataframe_to_CSVfile <- function(str_path, str_CSVfilename, df_dataframe, str_filenameExtension) {\n",
    "  # Split file name on second underscore, found here: \n",
    "  # https://stackoverflow.com/questions/32398427/r-split-a-character-string-on-the-second-underscore/32398489#32398489\n",
    "  list_str_split <- strsplit(sub('(^[^_]+_[^_]+)_(.*)$', '\\\\1 \\\\2', str_CSVfilename), ' ')\n",
    "  \n",
    "  # extend the file name prefix and glue together with old suffix\n",
    "  str_CSVfilename_extended <- paste(list_str_split[[1]][1], str_filenameExtension, list_str_split[[1]][2], sep=\"_\")\n",
    "  \n",
    "  # extend file name by path\n",
    "  str_CSVfilename_extended <- paste(str_path, str_CSVfilename_extended, sep=\"/\")\n",
    "  \n",
    "  write.table(df_dataframe, file = str_CSVfilename_extended,\n",
    "              fileEncoding = \"UTF-8\", row.names = FALSE,\n",
    "              col.names = TRUE, sep = \"\\t\", quote = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fe50e-af73-4659-931b-d9ac7f34ac02",
   "metadata": {},
   "source": [
    "# Manipulate the data and store in new CSV files for each criteria\n",
    "\n",
    "## Environmental sub-criteria\n",
    "\n",
    "Walk over all input CSV files, manipulate the data, and write the results to output CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a585b55c-41fc-4b9d-be31-bd4f2efdf85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_colnames_search_1 <- c('AU01', 'AU02', 'AU03')\n",
    "vec_colnames_search_2 <- c('RU01_01', 'RU02_01', 'RU03_01', 'RU04_01', 'RU05_01', 'RU06_01')\n",
    "vec_colnames_out <- c('Klima_BioV', 'Klima_KlW', 'BioV_KlW')\n",
    "\n",
    "for ( row_idx in 1:nrow(df_csvInputFiles) ) {\n",
    "  # create list of data frames from current input CSV file\n",
    "  str_filename <- paste(str_input_path, df_csvInputFiles[row_idx, filenames], sep=\"/\")\n",
    "  list_dataframes <- func_readCSVdata_to_dataframes(str_filename)\n",
    "  \n",
    "  # scramble the data frames\n",
    "  df_scrambledData <- func_scrambleData(list_dataframes[[1]], vec_colnames_search_1, vec_colnames_search_2, vec_colnames_out)\n",
    "  \n",
    "  # write scrambled data frames to output CSV file\n",
    "  func_writeDataframe_to_CSVfile(str_output_path, df_csvInputFiles[row_idx, filenames], df_scrambledData, \"env\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651dc078-6c3a-4268-99b1-183b01d9b6ca",
   "metadata": {},
   "source": [
    "## Social sub-criteria\n",
    "\n",
    "Walk over all input CSV files, manipulate the data, and write the results to output CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d64049a-9042-4869-8c6c-043435726769",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_colnames_search_1 <- c('AS01', 'AS02', 'AS03')\n",
    "vec_colnames_search_2 <- c('RS01_01', 'RS02_01', 'RS03_01', 'RS04_01', 'RS05_01', 'RS06_01')\n",
    "vec_colnames_out <- c('Wiss_Gem', 'Wiss_Bet', 'Gem_Bet')\n",
    "\n",
    "for ( row_idx in 1:nrow(df_csvInputFiles) ) {\n",
    "  # create list of data frames from current input CSV file\n",
    "  str_filename <- paste(str_input_path, df_csvInputFiles[row_idx, filenames], sep=\"/\")\n",
    "  list_dataframes <- func_readCSVdata_to_dataframes(str_filename)\n",
    "  \n",
    "  # scramble the data frames\n",
    "  df_scrambledData <- func_scrambleData(list_dataframes[[2]], vec_colnames_search_1, vec_colnames_search_2, vec_colnames_out)\n",
    "  \n",
    "  # write scrambled data frames to output CSV file\n",
    "  func_writeDataframe_to_CSVfile(str_output_path, df_csvInputFiles[row_idx, filenames], df_scrambledData, \"soc\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b42ec-288b-4b4b-8fef-0fbcd7ecb118",
   "metadata": {},
   "source": [
    "## Economic sub-criteria\n",
    "\n",
    "Walk over all input CSV files, manipulate the data, and write the results to output CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "602c734a-f4aa-47b7-b706-278b1e39f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_colnames_search_1 <- c('AW01', 'AW02', 'AW03')\n",
    "vec_colnames_search_2 <- c('RW01_01', 'RW02_01', 'RW03_01', 'RW04_01', 'RW05_01', 'RW06_01')\n",
    "vec_colnames_out <- c('Quali_WSK', 'Quali_Bez', 'WSK_Bez')\n",
    "\n",
    "for ( row_idx in 1:nrow(df_csvInputFiles) ) {\n",
    "  # create list of data frames from current input CSV file\n",
    "  str_filename <- paste(str_input_path, df_csvInputFiles[row_idx, filenames], sep=\"/\")\n",
    "  list_dataframes <- func_readCSVdata_to_dataframes(str_filename)\n",
    "  \n",
    "  # scramble the data frames\n",
    "  df_scrambledData <- func_scrambleData(list_dataframes[[3]], vec_colnames_search_1, vec_colnames_search_2, vec_colnames_out)\n",
    "  \n",
    "  # write scrambled data frames to output CSV file\n",
    "  func_writeDataframe_to_CSVfile(str_output_path, df_csvInputFiles[row_idx, filenames], df_scrambledData, \"eco\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09307342-dbf7-4019-ad47-b1ddd0a99e28",
   "metadata": {},
   "source": [
    "## Criteria (main criteria)\n",
    "\n",
    "Walk over all input CSV files, manipulate the data, and write the results to output CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dd50fb1-5320-472f-b43f-207d94a1f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_colnames_search_1 <- c('AK01', 'AK02', 'AK03')\n",
    "vec_colnames_search_2 <- c('RK01_01', 'RK02_01', 'RK03_01', 'RK04_01', 'RK05_01', 'RK06_01')\n",
    "vec_colnames_out <- c('Oeko_Soz', 'Oeko_Wirt', 'Soz_Wirt')\n",
    "\n",
    "for ( row_idx in 1:nrow(df_csvInputFiles) ) {\n",
    "  # create list of data frames from current input CSV file\n",
    "  str_filename <- paste(str_input_path, df_csvInputFiles[row_idx, filenames], sep=\"/\")\n",
    "  list_dataframes <- func_readCSVdata_to_dataframes(str_filename)\n",
    "  \n",
    "  # scramble the data frames\n",
    "  df_scrambledData <- func_scrambleData(list_dataframes[[4]], vec_colnames_search_1, vec_colnames_search_2, vec_colnames_out)\n",
    "  \n",
    "  # write scrambled data frames to output CSV file\n",
    "  func_writeDataframe_to_CSVfile(str_output_path, df_csvInputFiles[row_idx, filenames], df_scrambledData, \"crit\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b16c03-c6f7-4fa8-bc94-26f2529aa977",
   "metadata": {},
   "source": [
    "# Summary and outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874768f-4963-4cb5-870e-46b172104cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "abstract": "This is a placeholder for the abstract that needs to be added later.",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  },
  "latex_metadata": {
   "affiliation": "BG ETEM",
   "author": "Dipl.-Ing. Bj\\\"orn Kasper",
   "bib": "literature/notebook.bib",
   "cover_image": "images/Cover_image.pdf",
   "email": "kasper.bjoern@bgetem.de",
   "release_version": "version 0.1 (pre-release)",
   "title": "Preparing raw CSV input data from survey for analytical hierarchy process (AHP)"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
